TimeStamp: 0711_2125
 {
  "root": "./data/fakeNews/",
  "train": "./data/fakeNews/fulltrain.csv",
  "dev": "./data/fakeNews/balancedtest.csv",
  "test": "./data/fakeNews/test.xlsx",
  "pte": "",
  "entity_desc": "./data/fakeNews/entityDescCorpus.pkl",
  "entity_tran": "./data/fakeNews/entity_feature_transE.pkl",
  "adjs": "./data/fakeNews/adjs/",
  "emb_dim": 100,
  "hidden_dim": 100,
  "node_emb_dim": 32,
  "max_epochs": 10,
  "max_sent_len": 50,
  "max_sents_in_a_doc": 10000,
  "batch_size": 32,
  "lr": 0.001,
  "dropout": 0.5,
  "ntags": 4,
  "weight_decay": 1e-06,
  "pooling": "max",
  "model_file": "model_CompareNet_Max_DET_0711_2125.t7",
  "plot": 0,
  "mode": 0,
  "cuda": true,
  "device": 0,
  "HALF": true,
  "DEBUG": false,
  "node_type": 3,
  "repeat": 1,
  "seed": [
    5
  ],
  "config": "CompareNet_Max_DET_0711_2125"
}
Loading adj:  ./data/fakeNews/adjs//
Loading ./data/fakeNews/adjs//train/
Preprocessing ./data/fakeNews/adjs//train/
removed_idx of ./data/fakeNews/fulltrain.csv: 3657
Average train document length: 27.664402504591013
Maximum train document length: 973
Loading ./data/fakeNews/adjs//test/
Preprocessing ./data/fakeNews/adjs//test/
removed_idx of ./data/fakeNews/test.xlsx: []
Loading ./data/fakeNews/adjs//dev/
Preprocessing ./data/fakeNews/adjs//dev/
removed_idx of ./data/fakeNews/balancedtest.csv: 31
PreCost: 0:06:07



--------------------------- Repeat: 0 ---------------------------



---------------------------  Seed: 5  ---------------------------
-----------CompareNet_Max_DET_0711_2125-------------
Times of out of memory:  0
Epoch: 1, Train loss: 1.1314, Train acc: 0.6049, Dev loss: 1.0864, Dev acc: 0.6613
Times of out of memory:  0
Epoch: 2, Train loss: 0.9726, Train acc: 0.7696, Dev loss: 0.9813, Dev acc: 0.7713
Times of out of memory:  0
Epoch: 3, Train loss: 0.9109, Train acc: 0.8305, Dev loss: 0.9189, Dev acc: 0.8341
Times of out of memory:  0
Epoch: 4, Train loss: 0.8633, Train acc: 0.8797, Dev loss: 0.8873, Dev acc: 0.8616
Times of out of memory:  0
Epoch: 5, Train loss: 0.8337, Train acc: 0.9095, Dev loss: 0.8722, Dev acc: 0.8749
Times of out of memory:  0
Epoch: 6, Train loss: 0.8123, Train acc: 0.9315, Dev loss: 0.8584, Dev acc: 0.8861
Times of out of memory:  0
Epoch: 7, Train loss: 0.8006, Train acc: 0.9433, Dev loss: 0.8465, Dev acc: 0.8998
Times of out of memory:  0
Epoch: 8, Train loss: 0.7891, Train acc: 0.9548, Dev loss: 0.8400, Dev acc: 0.9035
Times of out of memory:  0
Epoch: 9, Train loss: 0.7816, Train acc: 0.9622, Dev loss: 0.8391, Dev acc: 0.9066
Times of out of memory:  0
Epoch: 10, Train loss: 0.7733, Train acc: 0.9707, Dev loss: 0.8215, Dev acc: 0.9256
-----------------------------------------
{'data_loading': 367.5582723, 'CompareNet_Max_DET_0711_2125': 663.8168431000001}
Total time taken (in seconds): 1035.4683495000002
{
  "root": "./data/fakeNews/",
  "train": "./data/fakeNews/fulltrain.csv",
  "dev": "./data/fakeNews/balancedtest.csv",
  "test": "./data/fakeNews/test.xlsx",
  "pte": "",
  "entity_desc": "./data/fakeNews/entityDescCorpus.pkl",
  "entity_tran": "./data/fakeNews/entity_feature_transE.pkl",
  "adjs": "./data/fakeNews/adjs/",
  "emb_dim": 100,
  "hidden_dim": 100,
  "node_emb_dim": 32,
  "max_epochs": 10,
  "max_sent_len": 50,
  "max_sents_in_a_doc": 10000,
  "batch_size": 32,
  "lr": 0.001,
  "dropout": 0.5,
  "ntags": 4,
  "weight_decay": 1e-06,
  "pooling": "max",
  "model_file": "model_CompareNet_Max_DET_0711_2125.t7",
  "plot": 0,
  "mode": 0,
  "cuda": true,
  "device": 0,
  "HALF": true,
  "DEBUG": false,
  "node_type": 3,
  "repeat": 1,
  "seed": [
    5
  ],
  "config": "CompareNet_Max_DET_0711_2125"
}
Accuracy on the OOD test set 2: 0.6379
Precision on the OOD test set 2 macro / micro: 0.6622, 0.6379
Recall on the OOD test set 2 macro / micro: 0.6368, 0.6379
F1 on the OOD test set 2 macro / micro: 0.6169, 0.6379
Latex: 63.79 & 66.22 & 63.68 & 61.69
----------------------------------------------------------------------
Accuracy on the dev set: 0.9256
Precision on the dev set macro / micro: 0.9289, 0.9256
Recall on the dev macro / micro: 0.9211, 0.9256
F1 on the dev macro / micro: 0.9244, 0.9256
Latex: 92.56 & 92.89 & 92.11 & 92.44
